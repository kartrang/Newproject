{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt\n",
        "\n",
        "\n",
        "- The input a user provides to an AI model to get a specific response\n",
        "- The format and structure does make a difference in quality of response.\n",
        "- Prompt should have\n",
        "    \n",
        "    - Proper instruction for model\n",
        "    - Clear and defined task\n",
        "    - Defined role for the model\n",
        "    - Only add just enough context for response generation\n",
        "\n",
        "\n",
        "- Format and structure can vary model-to-model\n",
        "- based on the training of model"
      ],
      "metadata": {
        "id": "pKgWivYK02L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Techniques:\n",
        "- Zero shot\n",
        "- Few shot\n",
        "- Chain of thought\n",
        "-"
      ],
      "metadata": {
        "id": "jiHeScAz2Mto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero Shot"
      ],
      "metadata": {
        "id": "2vKgbIMA2kp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
        "\n",
        "Text: I think the vacation is okay.\n",
        "Sentiment:\"\"\""
      ],
      "metadata": {
        "id": "s_qjsrBp2mk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdhgZRTL37w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-Shot"
      ],
      "metadata": {
        "id": "NRwWT-wK4qlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = \"\"\"A \"whatpu\" is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is:\n",
        "We were traveling in Africa and we saw these very cute whatpus.\n",
        "\n",
        "To do a \"farduddle\" means to jump up and down really fast. An example of a sentence that uses the word farduddle is:\"\"\"\n"
      ],
      "metadata": {
        "id": "w6Y9dttM4vkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain-of-thought"
      ],
      "metadata": {
        "id": "IPJFeHNs5S70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read: https://www.promptingguide.ai/techniques/cot"
      ],
      "metadata": {
        "id": "niZwR98VKQ7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain_of_thought_prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\"\"\""
      ],
      "metadata": {
        "id": "yPp2hejv5f_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v4uj9Sdr5rVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}